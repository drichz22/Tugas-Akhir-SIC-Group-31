{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/56/f886ed6f1777ffa9d54c6e80231b69db8a1f52dcc33f5967b06a105dcfe0/pandas-1.3.5-cp37-cp37m-win_amd64.whl (10.0MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\aldri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.21.6)\n",
      "Collecting pytz>=2017.3 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl (505kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\aldri\\appdata\\roaming\\python\\python37\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aldri\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.3.5 pytz-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 24.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete. Train and test datasets saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Get the current working directory and set the file path\n",
    "directory = os.getcwd()\n",
    "file_path = os.path.join(directory, 'temperature_humidity_data_contoh.csv')\n",
    "\n",
    "# Load the existing dataset\n",
    "existing_df = pd.read_csv(file_path)\n",
    "\n",
    "# Add label column\n",
    "existing_df['Label'] = ((existing_df['Temperature'] > 37) & (existing_df['Humidity'] > 90)).astype(int)\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_synthetic_data(num_rows, label_proportion=0.5):\n",
    "    num_label_1 = int(num_rows * label_proportion)\n",
    "    num_label_0 = num_rows - num_label_1\n",
    "\n",
    "    # Generate data for label 1 (smoking)\n",
    "    data_label_1 = {\n",
    "        'Timestamp': pd.date_range(start='2023-01-01', periods=num_label_1, freq='S'),\n",
    "        'Temperature': np.random.uniform(38, 45, num_label_1),  # Ensure temperature > 37\n",
    "        'Humidity': np.random.uniform(91, 100, num_label_1)     # Ensure humidity > 90\n",
    "    }\n",
    "\n",
    "    # Generate data for label 0 (not smoking)\n",
    "    data_label_0 = {\n",
    "        'Timestamp': pd.date_range(start='2023-01-01', periods=num_label_0, freq='S'),\n",
    "        'Temperature': np.random.uniform(20, 37, num_label_0),  # Ensure temperature <= 37\n",
    "        'Humidity': np.random.uniform(30, 90, num_label_0)      # Ensure humidity <= 90\n",
    "    }\n",
    "\n",
    "    # Combine the data\n",
    "    data_combined = {\n",
    "        'Timestamp': np.concatenate([data_label_1['Timestamp'], data_label_0['Timestamp']]),\n",
    "        'Temperature': np.concatenate([data_label_1['Temperature'], data_label_0['Temperature']]),\n",
    "        'Humidity': np.concatenate([data_label_1['Humidity'], data_label_0['Humidity']])\n",
    "    }\n",
    "\n",
    "    synthetic_df = pd.DataFrame(data_combined)\n",
    "    synthetic_df['Label'] = [1] * num_label_1 + [0] * num_label_0\n",
    "    return synthetic_df\n",
    "\n",
    "# Calculate how many rows we need to add\n",
    "rows_needed = 10000 - len(existing_df)\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_df = generate_synthetic_data(rows_needed)\n",
    "\n",
    "# Combine existing and synthetic data\n",
    "combined_df = pd.concat([existing_df, synthetic_df], ignore_index=True)\n",
    "\n",
    "# Split into training and testing sets (80/20 split)\n",
    "train_df = combined_df.sample(frac=0.8, random_state=42)\n",
    "test_df = combined_df.drop(train_df.index)\n",
    "\n",
    "# Save to CSV files\n",
    "train_file_path = os.path.join(directory, 'train.csv')\n",
    "test_file_path = os.path.join(directory, 'test.csv')\n",
    "train_df.to_csv(train_file_path, index=False)\n",
    "test_df.to_csv(test_file_path, index=False)\n",
    "\n",
    "print(\"Data preparation complete. Train and test datasets saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
